{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aurora2\n",
    "## 1. CNN을 이용한 문장 입력 이진분류 모델\n",
    "## 2. 영화 리뷰 50000개를 입력 데이터로 사용\n",
    "## 3. NLP와 Word2Vec 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing start...\n",
      "tokenizing complete\n",
      "종료시간:  2021-03-07 17:49:32.167454 \n",
      "소요시간:  0:03:36.782125 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stime1 = datetime.datetime.now()\n",
    "print(\"tokenizing start...\")\n",
    "\n",
    "review_lines = list()\n",
    "lines = df['review'].values.tolist()\n",
    "\n",
    "for line in lines:   \n",
    "    tokens = word_tokenize(line)\n",
    "    \n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    " \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    review_lines.append(words)\n",
    "    \n",
    "\n",
    "etime1 = datetime.datetime.now()\n",
    "mtime1 = etime1-stime1\n",
    "\n",
    "print(\"tokenizing complete\")\n",
    "print(\"종료시간: \",etime1,\"\\n소요시간: \",mtime1,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "\n",
    "EMBEDDING_DIM = 40\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM, window=3, workers=4, min_count=1)\n",
    "\n",
    "words = list(model.wv.vocab)\n",
    "\n",
    "filename = 'imdb_embedding_word2vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('terrible', 0.9643401503562927), ('awful', 0.9361155033111572), ('bad', 0.8692532777786255), ('pathetic', 0.8605937957763672), ('sucks', 0.8515067100524902), ('dreadful', 0.8395964503288269), ('horrendous', 0.8237969875335693), ('horrid', 0.8199545741081238), ('atrocious', 0.8172741532325745), ('sucked', 0.8026109337806702)]\n",
      "[('unsurprised', 0.8664793968200684), ('factoids', 0.8514717817306519), ('romeo', 0.8504727482795715), ('haggerd', 0.8501615524291992), ('tarzan', 0.8472567200660706), ('typeface', 0.8470250368118286), ('princess', 0.8384085893630981), ('areshe', 0.8366364240646362), ('nearbiographical', 0.8360018730163574), ('accentsomeone', 0.8332093358039856)]\n",
      "movie\n",
      "0.90771943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('horrible'))\n",
    "\n",
    "print(model.wv.most_similar_cosmul(positive=['woman', 'king'], negative=['man']))\n",
    "\n",
    "print(model.wv.doesnt_match(\"woman king queen movie\".split()))\n",
    "\n",
    "print(model.similarity('boy', 'girl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('', 'imdb_embedding_word2vec.txt'),  encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "X_train = df.loc[:24999, 'review'].values\n",
    "y_train = df.loc[:24999, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values\n",
    "\n",
    "total_reviews = X_train + X_test\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134095 unique tokens.\n",
      "Shape of review tensor: (50000, 200)\n",
      "Shape of sentiment tensor: (50000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
    "\n",
    "# pad sequences\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "sentiment =  df['sentiment'].values\n",
    "print('Shape of review tensor:', review_pad.shape)\n",
    "print('Shape of sentiment tensor:', sentiment.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])\n",
    "\n",
    "X_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train = sentiment[:-num_validation_samples]\n",
    "X_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test = sentiment[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134096\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 40\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 40)           5363840   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 196, 128)          25728     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 98, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 12545     \n",
      "=================================================================\n",
      "Total params: 5,418,625\n",
      "Trainable params: 54,785\n",
      "Non-trainable params: 5,363,840\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "45000/45000 - 36s - loss: 0.4381 - accuracy: 0.7915 - val_loss: 0.5730 - val_accuracy: 0.7354\n",
      "Epoch 2/5\n",
      "45000/45000 - 36s - loss: 0.3407 - accuracy: 0.8504 - val_loss: 0.3297 - val_accuracy: 0.8648\n",
      "Epoch 3/5\n",
      "45000/45000 - 37s - loss: 0.3000 - accuracy: 0.8730 - val_loss: 0.3288 - val_accuracy: 0.8612\n",
      "Epoch 4/5\n",
      "45000/45000 - 36s - loss: 0.2630 - accuracy: 0.8888 - val_loss: 0.3290 - val_accuracy: 0.8660\n",
      "Epoch 5/5\n",
      "45000/45000 - 37s - loss: 0.2289 - accuracy: 0.9056 - val_loss: 0.3692 - val_accuracy: 0.8458\n",
      "training complete\n",
      "종료시간:  2021-03-07 18:02:27.220041 \n",
      "소요시간:  0:03:02.220083 \n",
      "\n",
      "\n",
      "5000/5000 [==============================] - 1s 249us/sample - loss: 0.3692 - accuracy: 0.8458\n",
      "Accuracy: 84.58 %\n"
     ]
    }
   ],
   "source": [
    "stime2 = datetime.datetime.now()\n",
    "print(\"training start\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist= model.fit(X_train_pad, y_train, batch_size=64, epochs=5, validation_data=(X_test_pad, y_test), verbose=2)\n",
    "\n",
    "etime2 = datetime.datetime.now()\n",
    "mtime2 = etime2-stime2\n",
    "\n",
    "print(\"training complete\")\n",
    "print(\"종료시간: \",etime2,\"\\n소요시간: \",mtime2,'\\n\\n')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, batch_size=64)\n",
    "print('Accuracy: %.2f' % (accuracy*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d7b1152f0aae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'gold', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'g', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'r', label='val_acc')\n",
    "acc_ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "acc_ax.legend(loc='upper left')\n",
    "loss_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "positive\n",
      "0.84232014 \n",
      "\n",
      "2\n",
      "positive\n",
      "0.6982778 \n",
      "\n",
      "3\n",
      "negative\n",
      "0.42567056 \n",
      "\n",
      "4\n",
      "negative\n",
      "0.35140663 \n",
      "\n",
      "5\n",
      "negative\n",
      "0.45212618 \n",
      "\n",
      "6\n",
      "negative\n",
      "0.06734211 \n",
      "\n",
      "7\n",
      "positive\n",
      "0.6982778 \n",
      "\n",
      "8\n",
      "negative\n",
      "0.1294273 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sample_1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
    "test_sample_2 = \"Good movie!\"\n",
    "test_sample_3 = \"Maybe I like this movie.\"\n",
    "test_sample_4 = \"Not to my taste, will skip and watch another movie\"\n",
    "test_sample_5 = \"if you like action, then this movie might be good for you.\"\n",
    "test_sample_6 = \"Bad movie!\"\n",
    "test_sample_7 = \"Not a good movie!\" # 현제 모델의 한계: 특정 단어로 판별할 뿐, 앞 뒤 단어간 맥락을 완전히 읽지는 못한다.\n",
    "test_sample_8 = \"This movie really sucks! Can I get my money back please?\"\n",
    "test_samples = [test_sample_1, test_sample_2, test_sample_3, test_sample_4, test_sample_5, test_sample_6, test_sample_7, test_sample_8]\n",
    "\n",
    "test_samples_tokens = tokenizer_obj.texts_to_sequences(test_samples)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=200)\n",
    "\n",
    "#predict\n",
    "pred = model.predict(x=test_samples_tokens_pad)\n",
    "\n",
    "pr_count=0\n",
    "for i in pred :\n",
    "    pr_count += 1\n",
    "    print(pr_count)\n",
    "    if i[0] >= 0.55 :\n",
    "        print('positive')\n",
    "    else :\n",
    "        print('negative')\n",
    "    print(i[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
